{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "fc1_relu (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "fc4 (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "output_sigmoid (Dense)       (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 5,445\n",
      "Trainable params: 5,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inputs = Input(shape=(16,))\n",
    "x = Dense(64, activation='relu', kernel_initializer='lecun_uniform', name='fc1_relu')(Inputs)\n",
    "y = Dense(32, activation='relu', kernel_initializer='lecun_uniform', name = 'fc2')(x)\n",
    "z = Dense(32, activation='relu', kernel_initializer='lecun_uniform', name = 'fc3')(y)\n",
    "a = Dense(32, activation='relu', kernel_initializer='lecun_uniform', name='fc4')(z)\n",
    "predictions = Dense(5, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'output_sigmoid')(a)\n",
    "model = Model(inputs=Inputs, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\anrun\\\\Documents\\\\EPE ML\\\\Tutorial')\n",
    "f = h5py.File('processed-pythia82-lhc13-all-pt1-50k-r1_h022_e0175_t220_nonu_truth.z', 'r')\n",
    "treeArray = f['t_allpar_new'][()]\n",
    "\n",
    "features = ['j_zlogz', 'j_c1_b0_mmdt','j_c1_b1_mmdt', 'j_c1_b2_mmdt' , 'j_c2_b1_mmdt',\n",
    "            'j_c2_b2_mmdt', 'j_d2_b1_mmdt', 'j_d2_b2_mmdt', 'j_d2_a1_b1_mmdt', 'j_d2_a1_b2_mmdt', 'j_m2_b1_mmdt', 'j_m2_b2_mmdt', 'j_n2_b1_mmdt', \n",
    "            'j_n2_b2_mmdt', 'j_mass_mmdt', 'j_multiplicity']\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']\n",
    "features_labels_df = pd.DataFrame(treeArray, columns = features + labels)\n",
    "features_labels_df = features_labels_df.drop_duplicates()\n",
    "features_val = features_labels_df[features].values\n",
    "\n",
    "labels_val = features_labels_df[labels].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_val,labels_val,test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_val, labels_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 592083 samples, validate on 197361 samples\n",
      "Epoch 1/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.5440 - accuracy: 0.7957 - val_loss: 0.4370 - val_accuracy: 0.8090\n",
      "Epoch 2/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.4113 - accuracy: 0.8209 - val_loss: 0.3824 - val_accuracy: 0.8316\n",
      "Epoch 3/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3693 - accuracy: 0.8368 - val_loss: 0.3582 - val_accuracy: 0.8427\n",
      "Epoch 4/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3533 - accuracy: 0.8449 - val_loss: 0.3469 - val_accuracy: 0.8491\n",
      "Epoch 5/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3444 - accuracy: 0.8532 - val_loss: 0.3400 - val_accuracy: 0.8567\n",
      "Epoch 6/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3383 - accuracy: 0.8582 - val_loss: 0.3343 - val_accuracy: 0.8597\n",
      "Epoch 7/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3333 - accuracy: 0.8608 - val_loss: 0.3299 - val_accuracy: 0.8624\n",
      "Epoch 8/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3289 - accuracy: 0.8626 - val_loss: 0.3253 - val_accuracy: 0.8646\n",
      "Epoch 9/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3251 - accuracy: 0.8644 - val_loss: 0.3223 - val_accuracy: 0.8663\n",
      "Epoch 10/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3220 - accuracy: 0.8660 - val_loss: 0.3209 - val_accuracy: 0.8656\n",
      "Epoch 11/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3194 - accuracy: 0.8673 - val_loss: 0.3184 - val_accuracy: 0.8667\n",
      "Epoch 12/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3169 - accuracy: 0.8687 - val_loss: 0.3143 - val_accuracy: 0.8703\n",
      "Epoch 13/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3144 - accuracy: 0.8702 - val_loss: 0.3123 - val_accuracy: 0.8716\n",
      "Epoch 14/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3121 - accuracy: 0.8716 - val_loss: 0.3098 - val_accuracy: 0.8731\n",
      "Epoch 15/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3098 - accuracy: 0.8731 - val_loss: 0.3075 - val_accuracy: 0.8747\n",
      "Epoch 16/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3074 - accuracy: 0.8746 - val_loss: 0.3069 - val_accuracy: 0.8754\n",
      "Epoch 17/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3052 - accuracy: 0.8759 - val_loss: 0.3032 - val_accuracy: 0.8775\n",
      "Epoch 18/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3029 - accuracy: 0.8773 - val_loss: 0.3007 - val_accuracy: 0.8785\n",
      "Epoch 19/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.3007 - accuracy: 0.8786 - val_loss: 0.2990 - val_accuracy: 0.8799\n",
      "Epoch 20/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2987 - accuracy: 0.8798 - val_loss: 0.2966 - val_accuracy: 0.8811\n",
      "Epoch 21/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2967 - accuracy: 0.8809 - val_loss: 0.2949 - val_accuracy: 0.8820\n",
      "Epoch 22/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2948 - accuracy: 0.8819 - val_loss: 0.2928 - val_accuracy: 0.8831\n",
      "Epoch 23/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2932 - accuracy: 0.8827 - val_loss: 0.2917 - val_accuracy: 0.8838\n",
      "Epoch 24/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2915 - accuracy: 0.8835 - val_loss: 0.2905 - val_accuracy: 0.8841\n",
      "Epoch 25/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2901 - accuracy: 0.8841 - val_loss: 0.2897 - val_accuracy: 0.8843\n",
      "Epoch 26/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2889 - accuracy: 0.8847 - val_loss: 0.2876 - val_accuracy: 0.8853\n",
      "Epoch 27/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2877 - accuracy: 0.8852 - val_loss: 0.2862 - val_accuracy: 0.8858\n",
      "Epoch 28/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2868 - accuracy: 0.8855 - val_loss: 0.2852 - val_accuracy: 0.8867\n",
      "Epoch 29/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2858 - accuracy: 0.8859 - val_loss: 0.2854 - val_accuracy: 0.8859\n",
      "Epoch 30/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2850 - accuracy: 0.8862 - val_loss: 0.2846 - val_accuracy: 0.8864\n",
      "Epoch 31/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2844 - accuracy: 0.8864 - val_loss: 0.2846 - val_accuracy: 0.8865\n",
      "Epoch 32/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2837 - accuracy: 0.8867 - val_loss: 0.2822 - val_accuracy: 0.8873\n",
      "Epoch 33/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2830 - accuracy: 0.8869 - val_loss: 0.2812 - val_accuracy: 0.8878\n",
      "Epoch 34/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2825 - accuracy: 0.8872 - val_loss: 0.2807 - val_accuracy: 0.8879\n",
      "Epoch 35/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2818 - accuracy: 0.8873 - val_loss: 0.2810 - val_accuracy: 0.8876\n",
      "Epoch 36/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2814 - accuracy: 0.8875 - val_loss: 0.2801 - val_accuracy: 0.8877\n",
      "Epoch 37/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2811 - accuracy: 0.8875 - val_loss: 0.2793 - val_accuracy: 0.8885\n",
      "Epoch 38/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2805 - accuracy: 0.8878 - val_loss: 0.2799 - val_accuracy: 0.8886\n",
      "Epoch 39/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2803 - accuracy: 0.8879 - val_loss: 0.2791 - val_accuracy: 0.8882\n",
      "Epoch 40/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2797 - accuracy: 0.8882 - val_loss: 0.2784 - val_accuracy: 0.8886\n",
      "Epoch 41/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2795 - accuracy: 0.8882 - val_loss: 0.2781 - val_accuracy: 0.8884\n",
      "Epoch 42/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2789 - accuracy: 0.8885 - val_loss: 0.2776 - val_accuracy: 0.8888\n",
      "Epoch 43/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2787 - accuracy: 0.8885 - val_loss: 0.2788 - val_accuracy: 0.8882\n",
      "Epoch 44/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2784 - accuracy: 0.8886 - val_loss: 0.2778 - val_accuracy: 0.8887\n",
      "Epoch 45/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2782 - accuracy: 0.8886 - val_loss: 0.2767 - val_accuracy: 0.8893\n",
      "Epoch 46/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2778 - accuracy: 0.8889 - val_loss: 0.2766 - val_accuracy: 0.8892\n",
      "Epoch 47/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2775 - accuracy: 0.8890 - val_loss: 0.2765 - val_accuracy: 0.8892\n",
      "Epoch 48/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2773 - accuracy: 0.8890 - val_loss: 0.2757 - val_accuracy: 0.8897\n",
      "Epoch 49/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2770 - accuracy: 0.8891 - val_loss: 0.2756 - val_accuracy: 0.8899\n",
      "Epoch 50/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2768 - accuracy: 0.8892 - val_loss: 0.2791 - val_accuracy: 0.8880\n",
      "Epoch 51/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2766 - accuracy: 0.8892 - val_loss: 0.2760 - val_accuracy: 0.8899\n",
      "Epoch 52/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2763 - accuracy: 0.8895 - val_loss: 0.2752 - val_accuracy: 0.8901\n",
      "Epoch 53/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2762 - accuracy: 0.8894 - val_loss: 0.2745 - val_accuracy: 0.8899\n",
      "Epoch 54/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2758 - accuracy: 0.8896 - val_loss: 0.2749 - val_accuracy: 0.8900\n",
      "Epoch 55/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2757 - accuracy: 0.8896 - val_loss: 0.2746 - val_accuracy: 0.8904\n",
      "Epoch 56/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2755 - accuracy: 0.8897 - val_loss: 0.2740 - val_accuracy: 0.8905\n",
      "Epoch 57/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2753 - accuracy: 0.8898 - val_loss: 0.2740 - val_accuracy: 0.8904\n",
      "Epoch 58/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2749 - accuracy: 0.8900 - val_loss: 0.2760 - val_accuracy: 0.8892\n",
      "Epoch 59/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2749 - accuracy: 0.8900 - val_loss: 0.2787 - val_accuracy: 0.8880\n",
      "Epoch 60/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2747 - accuracy: 0.8900 - val_loss: 0.2783 - val_accuracy: 0.8883\n",
      "Epoch 61/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2745 - accuracy: 0.8901 - val_loss: 0.2736 - val_accuracy: 0.8903\n",
      "Epoch 62/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2743 - accuracy: 0.8901 - val_loss: 0.2726 - val_accuracy: 0.8909\n",
      "Epoch 63/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2742 - accuracy: 0.8902 - val_loss: 0.2732 - val_accuracy: 0.8908\n",
      "Epoch 64/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2741 - accuracy: 0.8902 - val_loss: 0.2765 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2738 - accuracy: 0.8904 - val_loss: 0.2731 - val_accuracy: 0.8908\n",
      "Epoch 66/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2735 - accuracy: 0.8904 - val_loss: 0.2734 - val_accuracy: 0.8903\n",
      "Epoch 67/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2736 - accuracy: 0.8904 - val_loss: 0.2723 - val_accuracy: 0.8908\n",
      "Epoch 68/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2733 - accuracy: 0.8905 - val_loss: 0.2718 - val_accuracy: 0.8908\n",
      "Epoch 69/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2734 - accuracy: 0.8905 - val_loss: 0.2732 - val_accuracy: 0.8908\n",
      "Epoch 70/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2729 - accuracy: 0.8907 - val_loss: 0.2718 - val_accuracy: 0.8912\n",
      "Epoch 71/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2727 - accuracy: 0.8908 - val_loss: 0.2719 - val_accuracy: 0.8910\n",
      "Epoch 72/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2728 - accuracy: 0.8907 - val_loss: 0.2727 - val_accuracy: 0.8907\n",
      "Epoch 73/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2724 - accuracy: 0.8908 - val_loss: 0.2708 - val_accuracy: 0.8916\n",
      "Epoch 74/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2724 - accuracy: 0.8908 - val_loss: 0.2720 - val_accuracy: 0.8912\n",
      "Epoch 75/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2723 - accuracy: 0.8909 - val_loss: 0.2722 - val_accuracy: 0.8909\n",
      "Epoch 76/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2722 - accuracy: 0.8909 - val_loss: 0.2740 - val_accuracy: 0.8902\n",
      "Epoch 77/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2720 - accuracy: 0.8911 - val_loss: 0.2724 - val_accuracy: 0.8909\n",
      "Epoch 78/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2719 - accuracy: 0.8910 - val_loss: 0.2714 - val_accuracy: 0.8916\n",
      "Epoch 79/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2716 - accuracy: 0.8912 - val_loss: 0.2710 - val_accuracy: 0.8914\n",
      "Epoch 80/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2716 - accuracy: 0.8912 - val_loss: 0.2716 - val_accuracy: 0.8910\n",
      "Epoch 81/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2714 - accuracy: 0.8913 - val_loss: 0.2698 - val_accuracy: 0.8920\n",
      "Epoch 82/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2712 - accuracy: 0.8914 - val_loss: 0.2695 - val_accuracy: 0.8919\n",
      "Epoch 83/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2710 - accuracy: 0.8916 - val_loss: 0.2706 - val_accuracy: 0.8916\n",
      "Epoch 84/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2709 - accuracy: 0.8915 - val_loss: 0.2711 - val_accuracy: 0.8917\n",
      "Epoch 85/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2707 - accuracy: 0.8916 - val_loss: 0.2720 - val_accuracy: 0.8911\n",
      "Epoch 86/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2705 - accuracy: 0.8917 - val_loss: 0.2735 - val_accuracy: 0.8901\n",
      "Epoch 87/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2709 - accuracy: 0.8915 - val_loss: 0.2707 - val_accuracy: 0.8916\n",
      "Epoch 88/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2703 - accuracy: 0.8918 - val_loss: 0.2695 - val_accuracy: 0.8920\n",
      "Epoch 89/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2702 - accuracy: 0.8918 - val_loss: 0.2705 - val_accuracy: 0.8913\n",
      "Epoch 90/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2702 - accuracy: 0.8918 - val_loss: 0.2719 - val_accuracy: 0.8910\n",
      "Epoch 91/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2700 - accuracy: 0.8919 - val_loss: 0.2708 - val_accuracy: 0.8916\n",
      "Epoch 92/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2700 - accuracy: 0.8920 - val_loss: 0.2691 - val_accuracy: 0.8928\n",
      "Epoch 93/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2696 - accuracy: 0.8921 - val_loss: 0.2682 - val_accuracy: 0.8927\n",
      "Epoch 94/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2695 - accuracy: 0.8922 - val_loss: 0.2690 - val_accuracy: 0.8923\n",
      "Epoch 95/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2695 - accuracy: 0.8922 - val_loss: 0.2728 - val_accuracy: 0.8904\n",
      "Epoch 96/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2693 - accuracy: 0.8922 - val_loss: 0.2692 - val_accuracy: 0.8924\n",
      "Epoch 97/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2691 - accuracy: 0.8924 - val_loss: 0.2692 - val_accuracy: 0.8925\n",
      "Epoch 98/100\n",
      "592083/592083 [==============================] - 1s 2us/step - loss: 0.2693 - accuracy: 0.8923 - val_loss: 0.2680 - val_accuracy: 0.8932\n",
      "Epoch 99/100\n",
      "592083/592083 [==============================] - 2s 3us/step - loss: 0.2689 - accuracy: 0.8925 - val_loss: 0.2675 - val_accuracy: 0.8928\n",
      "Epoch 100/100\n",
      "592083/592083 [==============================] - 1s 3us/step - loss: 0.2688 - accuracy: 0.8925 - val_loss: 0.2678 - val_accuracy: 0.8931\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 1024, epochs = 100, \n",
    "                    validation_split = 0.25, shuffle = True, callbacks = None,\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('4-layer') #Saves to local directory; model file 'two-layer' with no extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('4-layer') #Loads from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(history):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    #plt.savefig('Learning_curve.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = model.predict(features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels_val, labels, model, outputDir='', outputSuffix=''):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    labels_pred = model.predict(features_val)\n",
    "    df = pd.DataFrame()\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    plt.figure(figsize=(10,8))       \n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = labels_pred[:,i]\n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label],tpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.plot([0, 1], [0, 1], lw=1, color='black', linestyle='--')\n",
    "    #plt.semilogy()\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,'LSTM ROC Curve',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    #plt.savefig('%sROC_%s.pdf'%(outputDir, outputSuffix))\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = makeRoc(X_test, y_test, labels, model, outputSuffix='two-layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
