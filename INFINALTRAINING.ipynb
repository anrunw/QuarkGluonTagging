{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\anrun\\\\anaconda3\\\\envs\\\\EPE_ML\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\anrun\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-f29578d7-f880-4930-ab3d-1f8c72f7be9a.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import itertools\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "\n",
    "from generatorIN import InEventLoader\n",
    "import random\n",
    "import time\n",
    "print(sys.argv)\n",
    "args_sumO = bool(int(sys.argv[3])) if len(sys.argv)>3 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\anrun\\\\anaconda3\\\\envs\\\\EPE_ML\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '-f', 'C:\\\\Users\\\\anrun\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-f29578d7-f880-4930-ab3d-1f8c72f7be9a.json']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sys.argv)\n",
    "args_sumO = bool(int(sys.argv[3])) if len(sys.argv)>3 else False\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden, De, Do, \n",
    "                 fr_activation=0, fo_activation=0, fc_activation=0, optimizer = 0, verbose = False):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.P = len(params)\n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = De\n",
    "        self.Dx = 0\n",
    "        self.Do = Do\n",
    "        self.n_targets = n_targets\n",
    "        self.fr_activation = fr_activation\n",
    "        self.fo_activation = fo_activation\n",
    "        self.fc_activation = fc_activation\n",
    "        self.optimizer = optimizer\n",
    "        self.verbose = verbose\n",
    "        self.assign_matrices()\n",
    "\n",
    "        self.sum_O = args_sumO\n",
    "        self.Ra = torch.ones(self.Dr, self.Nr)\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, self.hidden)\n",
    "        self.fr2 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.fr3 = nn.Linear(int(self.hidden/2), self.De)\n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + self.De, self.hidden)\n",
    "        self.fo2 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.fo3 = nn.Linear(int(self.hidden/2), self.Do)\n",
    "        if self.sum_O:\n",
    "            self.fc1 = nn.Linear(self.Do *1, self.hidden)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(self.Do * self.N, self.hidden)\n",
    "        self.fc2 = nn.Linear(self.hidden, int(self.hidden/2))\n",
    "        self.fc3 = nn.Linear(int(self.hidden/2), self.n_targets)\n",
    "\n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "        self.Rr = Variable(self.Rr)\n",
    "        self.Rs = Variable(self.Rs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###\n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        if self.fr_activation ==2:\n",
    "            B = nn.functional.selu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.selu(self.fr2(B))\n",
    "            E = nn.functional.selu(self.fr3(B).view(-1, self.Nr, self.De))            \n",
    "        elif self.fr_activation ==1:\n",
    "            B = nn.functional.elu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.elu(self.fr2(B))\n",
    "            E = nn.functional.elu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        else:\n",
    "            B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.relu(self.fr2(B))\n",
    "            E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        C = torch.cat([x, Ebar], 1)\n",
    "        del Ebar\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###\n",
    "        if self.fo_activation ==2:\n",
    "            C = nn.functional.selu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.selu(self.fo2(C))\n",
    "            O = nn.functional.selu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        elif self.fo_activation ==1:\n",
    "            C = nn.functional.elu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.elu(self.fo2(C))\n",
    "            O = nn.functional.elu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        else:\n",
    "            C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.relu(self.fo2(C))\n",
    "            O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "        ## sum over the O matrix\n",
    "        if self.sum_O:\n",
    "            O = torch.sum( O, dim=1)\n",
    "        ### Classification MLP ###\n",
    "        if self.fc_activation ==2:\n",
    "            if self.sum_O:\n",
    "                N = nn.functional.selu(self.fc1(O.view(-1, self.Do * 1)))\n",
    "            else:\n",
    "                N = nn.functional.selu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.selu(self.fc2(N))       \n",
    "        elif self.fc_activation ==1:\n",
    "            if self.sum_O:\n",
    "                N = nn.functional.elu(self.fc1(O.view(-1, self.Do * 1)))\n",
    "            else:\n",
    "                N = nn.functional.elu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.elu(self.fc2(N))\n",
    "        else:\n",
    "            if self.sum_O:\n",
    "                N = nn.functional.relu(self.fc1(O.view(-1, self.Do * 1)))\n",
    "            else:\n",
    "                N = nn.functional.relu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.relu(self.fc2(N))\n",
    "        del O\n",
    "        #N = nn.functional.relu(self.fc3(N))\n",
    "        N = self.fc3(N)\n",
    "        return N\n",
    "\n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])\n",
    "\n",
    "####################\n",
    "    \n",
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 50000)\n",
    "    return training[chosen_ind], target[chosen_ind]\n",
    "\n",
    "def accuracy(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    r = torch.sum(target == p_vals.squeeze(1)).data.numpy()[0]\n",
    "    t = target.size()[0]\n",
    "    return r * 1.0 / t\n",
    "\n",
    "def stats(predict, target):\n",
    "    print(predict)\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    t = target.cpu().data.numpy()\n",
    "    p_vals = p_vals.squeeze(1).data.numpy()\n",
    "    vals = np.unique(t)\n",
    "    for i in vals:\n",
    "        ind = np.where(t == i)\n",
    "        pv = p_vals[ind]\n",
    "        correct = sum(pv == t[ind])\n",
    "        print(\"  Target %s: %s/%s = %s%%\" % (i, correct, len(pv), correct * 100.0/len(pv)))\n",
    "    print(\"Overall: %s/%s = %s%%\" % (sum(p_vals == t), len(t), sum(p_vals == t) * 100.0/len(t)))\n",
    "    return sum(p_vals == t) * 100.0/len(t)\n",
    "\n",
    "best_perf = {\n",
    "    30 : [50, 12,  6,  0,  2,  2,  0], #L 0.63\n",
    "    50 : [50, 12, 14,  1,  2,  1,  0], #L 0.57\n",
    "    100: [30, 10, 10,  1,  1,  1,  0], #L 0.56\n",
    "    150: [10,  4, 14,  2,  2,  2,  0]  #L 0.62\n",
    "}\n",
    "sumO_best_perf = {\n",
    "    30 : [ 6,  8,  6, 0, 1, 1, 0], #L 0.84\n",
    "    50 : [50, 12, 14, 0, 0, 2, 0], #L 0.58\n",
    "    100: [30,  4,  4, 2, 0, 2, 0], #L 0.62\n",
    "    150: [50, 14, 10, 2, 2, 2, 0]  #L 0.55\n",
    "}\n",
    "# ### Prepare Dataset\n",
    "nParticles = 30\n",
    "x = sumO_best_perf[nParticles] if args_sumO else best_perf[nParticles]\n",
    "#nParticles = 100\n",
    "#x = []\n",
    "#x.append(50) # hinned nodes\n",
    "#x.append(12) # De\n",
    "#x.append(4) # Do\n",
    "#x.append(2) # fr_activation_index\n",
    "#x.append(0) # fo_activation_index\n",
    "#x.append(0) # fc_activation_index\n",
    "#x.append(0) # optmizer_index\n",
    "\n",
    "#####\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']\n",
    "params = ['j1_px', 'j1_py' , 'j1_pz' , 'j1_e' , 'j1_erel' , 'j1_pt' , 'j1_ptrel', 'j1_eta' , 'j1_etarel' , \n",
    "          'j1_etarot' , 'j1_phi' , 'j1_phirel' , 'j1_phirot', 'j1_deltaR' , 'j1_costheta' , 'j1_costhetarel']\n",
    "\n",
    "val_split = 0.3\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "patience = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#### LIST OF TRAINING FILES\n",
    "inputTrainFiles = glob.glob(\"../data2/Training/jetImage*_%sp*.h5\" %nParticles)\n",
    "#### LIST OF VALIDATION FILES\n",
    "inputValFiles = glob.glob(\"../data2/Validation/jetImage*_%sp*.h5\" %nParticles)\n",
    "\n",
    "mymodel = GraphNet(nParticles, len(labels), params, int(x[0]), int(x[1]), int(x[2]), \n",
    "                   fr_activation=int(x[3]),  fo_activation=int(x[4]), fc_activation=int(x[5]), optimizer=int(x[6]), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data2/Validation\\\\jetImage_7_30p_0_10000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_10000_20000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_20000_30000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_30000_40000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_40000_50000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_50000_60000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_60000_70000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_70000_80000.h5',\n",
       " '../data2/Validation\\\\jetImage_7_30p_80000_90000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_0_10000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_10000_20000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_20000_30000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_30000_40000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_40000_50000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_50000_60000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_60000_70000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_70000_80000.h5',\n",
       " '../data2/Validation\\\\jetImage_8_30p_80000_90000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_0_10000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_10000_20000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_20000_30000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_30000_40000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_40000_50000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_50000_60000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_60000_70000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_70000_80000.h5',\n",
       " '../data2/Validation\\\\jetImage_9_30p_80000_90000.h5']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputValFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']  # this is a classifier\n",
    "params = ['j1_px', 'j1_py' , 'j1_pz' , 'j1_e' , 'j1_erel' , 'j1_pt' , 'j1_ptrel', 'j1_eta' , 'j1_etarel' , \n",
    "          'j1_etarot' , 'j1_phi' , 'j1_phirel' , 'j1_phirot', 'j1_deltaR' , 'j1_costheta' , 'j1_costhetarel'] # these are the features in the graph\n",
    "\n",
    "val_split = 0.3\n",
    "batch_size = 100\n",
    "n_epochs = 100\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nParticles = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nBatches_per_training_epoch: 6100\n",
      "nBatches_per_validation_epoch: 2700\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "if mymodel.optimizer == 1:        \n",
    "    optimizer = optim.Adadelta(mymodel.parameters(), lr = 0.0001)\n",
    "else:\n",
    "    optimizer = optim.Adam(mymodel.parameters(), lr = 0.0001)\n",
    "loss_train = np.zeros(n_epochs)\n",
    "loss_val = np.zeros(n_epochs)\n",
    "nBatches_per_training_epoch = len(inputTrainFiles)*10000/batch_size\n",
    "nBatches_per_validation_epoch = len(inputValFiles)*10000/batch_size\n",
    "print(\"nBatches_per_training_epoch: %i\" %nBatches_per_training_epoch)\n",
    "print(\"nBatches_per_validation_epoch: %i\" %nBatches_per_validation_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   Loss: 1.316708\n",
      "Validation Loss: 1.195144\n",
      "918.6885328292847\n",
      "1\n",
      "Epoch 1\n",
      "Training   Loss: 1.103287\n",
      "Validation Loss: 1.045508\n",
      "926.4316155910492\n",
      "2\n",
      "Epoch 2\n",
      "Training   Loss: 1.022115\n",
      "Validation Loss: 0.982806\n",
      "996.0104382038116\n",
      "3\n",
      "Epoch 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    print(i)\n",
    "    start = time.time()\n",
    "    if mymodel.verbose: print(\"Epoch %s\" % i)\n",
    "    # Define the data generators from the training set and validation set.\n",
    "    random.shuffle(inputTrainFiles)\n",
    "    random.shuffle(inputValFiles)\n",
    "    train_set = InEventLoader(file_names=inputTrainFiles, nP=nParticles,\n",
    "                              feature_name ='jetConstituentList',label_name = 'jets', verbose=False)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "    val_set = InEventLoader(file_names=inputValFiles, nP=nParticles,\n",
    "                            feature_name ='jetConstituentList',label_name = 'jets', verbose=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    ####\n",
    "    # train\n",
    "    for batch_idx, mydict in enumerate(train_loader):\n",
    "        data = mydict['jetConstituentList']\n",
    "        target = mydict['jets']\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out = mymodel(data)\n",
    "        l = loss(out, target)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_train[i] += l.cpu().data.numpy()/nBatches_per_training_epoch\n",
    "    # validation\n",
    "    for batch_idx, mydict in enumerate(val_loader):\n",
    "        data = mydict['jetConstituentList']\n",
    "        target = mydict['jets']\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        out_val = mymodel(data)\n",
    "        l_val = loss(out_val, target)\n",
    "        loss_val[i] += l_val.cpu().data.numpy()/nBatches_per_validation_epoch\n",
    "    if mymodel.verbose: print(\"Training   Loss: %f\" %loss_train[i])\n",
    "    if mymodel.verbose: print(\"Validation Loss: %f\" %loss_val[i])\n",
    "    if all(loss_val[max(0, i - patience):i] > min(np.append(loss_val[0:max(0, i - patience)], 200))) and i > patience:\n",
    "        print(\"Early Stopping at\",i)\n",
    "        break\n",
    "        #that above does not trigger soon enough        \n",
    "    if i > (2*patience):\n",
    "        last_avg = np.mean(loss_val[i - patience:i])\n",
    "        previous_avg = np.mean(loss_val[i - 2*patience : i - patience])\n",
    "        if last_avg > previous_avg:\n",
    "            print(\"Early Avg Stopping at\",i)\n",
    "            break\n",
    "    if i > patience:\n",
    "        last_min = min(loss_val[i - patience:i])\n",
    "        overall_min = min(loss_val[:i-patience])\n",
    "        if last_min > overall_min:\n",
    "            print(\"Early min Stopping at\",i)\n",
    "            break\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py,os\n",
    "loc='IN_kFold_%s'%(sys.argv[1])\n",
    "os.system('mkdir %s'%loc)\n",
    "f = h5py.File(\"%s/history%s.h5\" %(loc, '_sumO' if mymodel.sum_O else ''), \"w\")\n",
    "f.create_dataset('train_loss', data= np.asarray(loss_train), compression='gzip')\n",
    "f.create_dataset('val_loss', data= np.asarray(loss_val), compression='gzip')\n",
    "\n",
    "# the best model\n",
    "torch.save(mymodel.state_dict(), \"%s/IN%s_bestmodel.params\" %(loc, '_sumO' if mymodel.sum_O else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Validation\\jetImage_5_30p_20000_30000.h5\n",
      "4800000\n",
      "(10000, 30, 16) (10000, 5)\n",
      "../data/Validation\\jetImage_5_30p_40000_50000.h5\n",
      "4800000\n",
      "(20000, 30, 16) (20000, 5)\n",
      "../data/Validation\\jetImage_4_30p_50000_60000.h5\n",
      "4800000\n",
      "(30000, 30, 16) (30000, 5)\n",
      "../data/Validation\\jetImage_6_30p_10000_20000.h5\n",
      "4800000\n",
      "(40000, 30, 16) (40000, 5)\n",
      "../data/Validation\\jetImage_5_30p_80000_90000.h5\n",
      "4800000\n",
      "(50000, 30, 16) (50000, 5)\n",
      "../data/Validation\\jetImage_6_30p_50000_60000.h5\n",
      "4800000\n",
      "(60000, 30, 16) (60000, 5)\n",
      "../data/Validation\\jetImage_6_30p_70000_80000.h5\n",
      "4800000\n",
      "(70000, 30, 16) (70000, 5)\n",
      "../data/Validation\\jetImage_6_30p_40000_50000.h5\n",
      "4800000\n",
      "(80000, 30, 16) (80000, 5)\n",
      "../data/Validation\\jetImage_6_30p_80000_90000.h5\n",
      "4800000\n",
      "(90000, 30, 16) (90000, 5)\n",
      "../data/Validation\\jetImage_6_30p_30000_40000.h5\n",
      "4800000\n",
      "(100000, 30, 16) (100000, 5)\n",
      "../data/Validation\\jetImage_5_30p_30000_40000.h5\n",
      "4800000\n",
      "(110000, 30, 16) (110000, 5)\n",
      "../data/Validation\\jetImage_6_30p_60000_70000.h5\n",
      "4800000\n",
      "(120000, 30, 16) (120000, 5)\n",
      "../data/Validation\\jetImage_5_30p_50000_60000.h5\n",
      "4800000\n",
      "(130000, 30, 16) (130000, 5)\n",
      "../data/Validation\\jetImage_4_30p_80000_90000.h5\n",
      "4800000\n",
      "(140000, 30, 16) (140000, 5)\n",
      "../data/Validation\\jetImage_6_30p_0_10000.h5\n",
      "4800000\n",
      "(150000, 30, 16) (150000, 5)\n",
      "../data/Validation\\jetImage_5_30p_70000_80000.h5\n",
      "4800000\n",
      "(160000, 30, 16) (160000, 5)\n",
      "../data/Validation\\jetImage_5_30p_0_10000.h5\n",
      "4800000\n",
      "(170000, 30, 16) (170000, 5)\n",
      "../data/Validation\\jetImage_5_30p_10000_20000.h5\n",
      "4800000\n",
      "(180000, 30, 16) (180000, 5)\n",
      "../data/Validation\\jetImage_4_30p_60000_70000.h5\n",
      "4800000\n",
      "(190000, 30, 16) (190000, 5)\n",
      "../data/Validation\\jetImage_5_30p_60000_70000.h5\n",
      "4800000\n",
      "(200000, 30, 16) (200000, 5)\n",
      "../data/Validation\\jetImage_4_30p_70000_80000.h5\n",
      "4800000\n",
      "(210000, 30, 16) (210000, 5)\n",
      "../data/Validation\\jetImage_6_30p_20000_30000.h5\n",
      "4800000\n",
      "(220000, 30, 16) (220000, 5)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Training\\\\jetImage_4_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_40000_50000.h5']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-40c5afb67042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mOtot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmyO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5f29f792e3d7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mOrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mOrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5f29f792e3d7>\u001b[0m in \u001b[0;36mtmul\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mx_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0my_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-2c85386f9253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m             raise RuntimeError(\n\u001b[0;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
