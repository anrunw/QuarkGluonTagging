{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import itertools\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import *\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import generatorIN\n",
    "from generatorIN import InEventLoader\n",
    "import time\n",
    "args_cuda = bool(sys.argv[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the pytorch model\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, n_constituents, n_targets, params, hidden, De, Do,\n",
    "                 fr_activation=0, fo_activation=0, fc_activation=0, optimizer = 0, verbose = False):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.P = len(params)\n",
    "        self.N = n_constituents\n",
    "        self.Nr = self.N * (self.N - 1)\n",
    "        self.Dr = 0\n",
    "        self.De = De\n",
    "        self.Dx = 0\n",
    "        self.Do = Do\n",
    "        self.n_targets = n_targets\n",
    "        self.fr_activation = fr_activation\n",
    "        self.fo_activation = fo_activation\n",
    "        self.fc_activation = fc_activation\n",
    "        self.optimizer = optimizer\n",
    "        self.verbose = verbose\n",
    "        self.assign_matrices()\n",
    "\n",
    "        self.Ra = torch.ones(self.Dr, self.Nr)\n",
    "\n",
    "        self.fr1 = nn.Linear(2 * self.P + self.Dr, hidden)\n",
    "        self.fr2 = nn.Linear(hidden, int(hidden/2))\n",
    "        self.fr3 = nn.Linear(int(hidden/2), self.De)\n",
    "        self.fo1 = nn.Linear(self.P + self.Dx + self.De, hidden)\n",
    "        self.fo2 = nn.Linear(hidden, int(hidden/2))\n",
    "        self.fo3 = nn.Linear(int(hidden/2), self.Do)\n",
    "        self.fc1 = nn.Linear(self.Do * self.N, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, int(hidden/2))\n",
    "        self.fc3 = nn.Linear(int(hidden/2), self.n_targets)\n",
    "\n",
    "    def assign_matrices(self):\n",
    "        self.Rr = torch.zeros(self.N, self.Nr)\n",
    "        self.Rs = torch.zeros(self.N, self.Nr)\n",
    "        receiver_sender_list = [i for i in itertools.product(range(self.N), range(self.N)) if i[0]!=i[1]]\n",
    "        for i, (r, s) in enumerate(receiver_sender_list):\n",
    "            self.Rr[r, i] = 1\n",
    "            self.Rs[s, i] = 1\n",
    "            self.Rr = Variable(self.Rr)\n",
    "            self.Rs = Variable(self.Rs)            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        Orr = self.tmul(x, self.Rr)\n",
    "        Ors = self.tmul(x, self.Rs)\n",
    "        B = torch.cat([Orr, Ors], 1)\n",
    "        ### First MLP ###                                                                                               \n",
    "        B = torch.transpose(B, 1, 2).contiguous()\n",
    "        if self.fr_activation ==2:\n",
    "            B = nn.functional.selu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.selu(self.fr2(B))\n",
    "            E = nn.functional.selu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        elif self.fr_activation ==1:\n",
    "            B = nn.functional.elu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.elu(self.fr2(B))\n",
    "            E = nn.functional.elu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        else:\n",
    "            B = nn.functional.relu(self.fr1(B.view(-1, 2 * self.P + self.Dr)))\n",
    "            B = nn.functional.relu(self.fr2(B))\n",
    "            E = nn.functional.relu(self.fr3(B).view(-1, self.Nr, self.De))\n",
    "        del B\n",
    "        E = torch.transpose(E, 1, 2).contiguous()\n",
    "        Ebar = self.tmul(E, torch.transpose(self.Rr, 0, 1).contiguous())\n",
    "        del E\n",
    "        C = torch.cat([x, Ebar], 1)\n",
    "        del Ebar\n",
    "        C = torch.transpose(C, 1, 2).contiguous()\n",
    "        ### Second MLP ###                                                                                              \n",
    "        if self.fo_activation ==2:\n",
    "            C = nn.functional.selu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.selu(self.fo2(C))\n",
    "            O = nn.functional.selu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        elif self.fo_activation ==1:\n",
    "            C = nn.functional.elu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.elu(self.fo2(C))\n",
    "            O = nn.functional.elu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        else:\n",
    "            C = nn.functional.relu(self.fo1(C.view(-1, self.P + self.Dx + self.De)))\n",
    "            C = nn.functional.relu(self.fo2(C))\n",
    "            O = nn.functional.relu(self.fo3(C).view(-1, self.N, self.Do))\n",
    "        del C\n",
    "        ### Classification MLP ###                                                                                      \n",
    "        if self.fc_activation ==2:\n",
    "            N = nn.functional.selu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.selu(self.fc2(N))\n",
    "        elif self.fc_activation ==1:\n",
    "            N = nn.functional.elu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.elu(self.fc2(N))\n",
    "        else:\n",
    "            N = nn.functional.relu(self.fc1(O.view(-1, self.Do * self.N)))\n",
    "            N = nn.functional.relu(self.fc2(N))\n",
    "        #del O\n",
    "        #N = nn.functional.relu(self.fc3(N))                                                                            \n",
    "        N = self.fc3(N)\n",
    "        return N, O\n",
    "\n",
    "    def tmul(self, x, y):  #Takes (I * J * K)(K * L) -> I * J * L                                                       \n",
    "        x_shape = x.size()\n",
    "        y_shape = y.size()\n",
    "        return torch.mm(x.view(-1, x_shape[2]), y).view(-1, x_shape[1], y_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(training, target, choice):\n",
    "    target_vals = np.argmax(target, axis = 1)\n",
    "    ind, = np.where(target_vals == choice)\n",
    "    chosen_ind = np.random.choice(ind, 50000)\n",
    "    return training[chosen_ind], target[chosen_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predict, target):\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    r = torch.sum(target == p_vals.squeeze(1)).data.numpy()[0]\n",
    "    t = target.size()[0]\n",
    "    return r * 1.0 / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(predict, target):\n",
    "    print(predict)\n",
    "    _, p_vals = torch.max(predict, 1)\n",
    "    t = target.cpu().data.numpy()\n",
    "    p_vals = p_vals.squeeze(1).data.numpy()\n",
    "    vals = np.unique(t)\n",
    "    for i in vals:\n",
    "        ind = np.where(t == i)\n",
    "        pv = p_vals[ind]\n",
    "        correct = sum(pv == t[ind])\n",
    "        print(\"  Target %s: %s/%s = %s%%\" % (i, correct, len(pv), correct * 100.0/len(pv)))\n",
    "    print(\"Overall: %s/%s = %s%%\" % (sum(p_vals == t), len(t), sum(p_vals == t) * 100.0/len(t)))\n",
    "    return sum(p_vals == t) * 100.0/len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGraphVtx = 30\n",
    "hidden_nodes = 20\n",
    "De = 3\n",
    "Do = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "labels = ['j_g', 'j_q', 'j_w', 'j_z', 'j_t']  # this is a classifier\n",
    "params = ['j1_px', 'j1_py' , 'j1_pz' , 'j1_e' , 'j1_erel' , 'j1_pt' , 'j1_ptrel', 'j1_eta' , 'j1_etarel' , \n",
    "          'j1_etarot' , 'j1_phi' , 'j1_phirel' , 'j1_phirot', 'j1_deltaR' , 'j1_costheta' , 'j1_costhetarel'] # these are the features in the graph\n",
    "\n",
    "val_split = 0.3\n",
    "batch_size = 100\n",
    "n_epochs = 100\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nParticles = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "#### LIST OF TRAINING FILES\n",
    "inputTrainFiles = glob.glob(\"../data/Training/jetImage*_%sp*.h5\" %nParticles)\n",
    "#### LIST OF VALIDATION FILES\n",
    "inputValFiles = glob.glob(\"../data/Validation/jetImage*_%sp*.h5\" %nParticles)\n",
    "\n",
    "mymodel = GraphNet(nGraphVtx, len(labels), params, hidden_nodes, De, Do, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "if mymodel.optimizer == 1:        \n",
    "    optimizer = optim.Adadelta(mymodel.parameters(), lr = 0.0001)\n",
    "else:\n",
    "    optimizer = optim.Adam(mymodel.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nBatches_per_training_epoch: 3900\n",
      "nBatches_per_validation_epoch: 2200\n"
     ]
    }
   ],
   "source": [
    "loss_train = np.zeros(n_epochs)\n",
    "loss_val = np.zeros(n_epochs)\n",
    "nBatches_per_training_epoch = len(inputTrainFiles)*10000/batch_size\n",
    "nBatches_per_validation_epoch = len(inputValFiles)*10000/batch_size\n",
    "print(\"nBatches_per_training_epoch: %i\" %nBatches_per_training_epoch)\n",
    "print(\"nBatches_per_validation_epoch: %i\" %nBatches_per_validation_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anrun\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-303.71861457824707\n",
      "1\n",
      "-300.45164155960083\n",
      "2\n",
      "-302.4614453315735\n",
      "3\n",
      "-305.07146883010864\n",
      "4\n",
      "-308.77799701690674\n",
      "5\n",
      "-301.9152693748474\n",
      "6\n",
      "-315.9819757938385\n",
      "7\n",
      "-339.23446249961853\n",
      "8\n",
      "-329.7103018760681\n",
      "9\n",
      "-325.25540113449097\n",
      "10\n",
      "-364.78473114967346\n",
      "11\n",
      "-349.32059693336487\n",
      "12\n",
      "-365.6239881515503\n",
      "13\n",
      "-322.428395986557\n",
      "14\n",
      "-326.0940935611725\n",
      "15\n",
      "-325.25250482559204\n",
      "16\n",
      "-322.30002331733704\n",
      "17\n",
      "-312.29039454460144\n",
      "18\n",
      "-308.01187658309937\n",
      "19\n",
      "-310.6941719055176\n",
      "20\n",
      "-296.66531562805176\n",
      "21\n",
      "-297.48386096954346\n",
      "22\n",
      "-299.8619635105133\n",
      "23\n",
      "-295.04224944114685\n",
      "24\n",
      "-297.6647391319275\n",
      "25\n",
      "-295.13219571113586\n",
      "26\n",
      "-295.0752286911011\n",
      "27\n",
      "-299.490642786026\n",
      "28\n",
      "-296.35049533843994\n",
      "29\n",
      "-294.8173773288727\n",
      "30\n",
      "-295.3080973625183\n",
      "31\n",
      "-295.2561230659485\n",
      "32\n",
      "-294.9713077545166\n",
      "33\n",
      "-294.90730690956116\n",
      "34\n",
      "-294.7803997993469\n",
      "35\n",
      "-294.3906216621399\n",
      "36\n",
      "-295.3150911331177\n",
      "37\n",
      "-294.04482197761536\n",
      "38\n",
      "-293.23928594589233\n",
      "39\n",
      "-293.32023882865906\n",
      "40\n",
      "-292.9984242916107\n",
      "41\n",
      "-297.15902972221375\n",
      "42\n",
      "-295.2591230869293\n",
      "43\n",
      "-294.94030714035034\n",
      "44\n",
      "-295.48599338531494\n",
      "45\n",
      "-295.65089869499207\n",
      "46\n",
      "-295.0172815322876\n",
      "47\n",
      "-295.70984506607056\n",
      "48\n",
      "-295.3640630245209\n",
      "49\n",
      "-295.3790545463562\n",
      "50\n",
      "-295.3080949783325\n",
      "51\n",
      "-295.07522988319397\n",
      "52\n",
      "-295.28011202812195\n",
      "53\n",
      "-295.60892057418823\n",
      "54\n",
      "-295.2981014251709\n",
      "55\n",
      "-295.5809381008148\n",
      "56\n",
      "-295.2811107635498\n",
      "57\n",
      "-295.72685527801514\n",
      "58\n",
      "-295.10021448135376\n",
      "59\n",
      "-295.4270260334015\n",
      "60\n",
      "-295.0602388381958\n",
      "61\n",
      "-295.8627760410309\n",
      "62\n",
      "-295.47799801826477\n",
      "63\n",
      "-295.13219571113586\n",
      "64\n",
      "-295.19516038894653\n",
      "65\n",
      "-295.3180890083313\n",
      "66\n",
      "-296.40846276283264\n",
      "67\n",
      "-295.3320813179016\n",
      "68\n",
      "-295.85378098487854\n",
      "69\n",
      "-295.85178422927856\n",
      "70\n",
      "-295.79781198501587\n",
      "71\n",
      "-296.15660643577576\n",
      "72\n",
      "-295.55795311927795\n",
      "73\n",
      "-295.6079213619232\n",
      "74\n",
      "-296.47942090034485\n",
      "75\n",
      "-296.55138063430786\n",
      "76\n",
      "-295.8927583694458\n",
      "77\n",
      "-295.6568956375122\n",
      "78\n",
      "-296.2545495033264\n",
      "79\n",
      "-295.7728295326233\n",
      "80\n",
      "-296.06265926361084\n",
      "81\n",
      "-295.40403985977173\n",
      "82\n",
      "-296.050669670105\n",
      "83\n",
      "-295.9167432785034\n",
      "84\n",
      "-295.74184560775757\n",
      "85\n",
      "-297.8136537075043\n",
      "86\n",
      "-295.4000425338745\n",
      "87\n",
      "-295.35308814048767\n",
      "88\n",
      "-294.9262959957123\n",
      "89\n",
      "-295.0392498970032\n",
      "90\n",
      "-295.0582387447357\n",
      "91\n",
      "-294.66646432876587\n",
      "92\n",
      "-295.6608922481537\n",
      "93\n",
      "-294.9443235397339\n",
      "94\n",
      "-295.9986798763275\n",
      "95\n",
      "-294.76142835617065\n",
      "96\n",
      "-295.5829381942749\n",
      "97\n",
      "-296.2385587692261\n",
      "98\n",
      "-296.37847924232483\n",
      "99\n",
      "-296.4254536628723\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epochs):\n",
    "    print(i)\n",
    "    start = time.time()\n",
    "    if mymodel.verbose: print(\"Epoch %s\" % i)\n",
    "    # Define the data generators from the training set and validation set.\n",
    "    random.shuffle(inputTrainFiles)\n",
    "    random.shuffle(inputValFiles)\n",
    "    train_set = InEventLoader(file_names=inputTrainFiles, nP=nParticles,\n",
    "                              feature_name ='jetConstituentList',label_name = 'jets', verbose=False)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "    val_set = InEventLoader(file_names=inputValFiles, nP=nParticles,\n",
    "                            feature_name ='jetConstituentList',label_name = 'jets', verbose=False)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "    ####\n",
    "    # train\n",
    "    for batch_idx, mydict in enumerate(train_loader):\n",
    "        data = mydict['jetConstituentList']\n",
    "        target = mydict['jets']\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out, hidden = mymodel(data)\n",
    "        l = loss(out, target)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        loss_train[i] += l.cpu().data.numpy()/nBatches_per_training_epoch\n",
    "    # validation\n",
    "    for batch_idx, mydict in enumerate(val_loader):\n",
    "        data = mydict['jetConstituentList']\n",
    "        target = mydict['jets']\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        out_val, hidden = mymodel(data)\n",
    "        l_val = loss(out_val, target)\n",
    "        loss_val[i] += l_val.cpu().data.numpy()/nBatches_per_validation_epoch\n",
    "    if mymodel.verbose: print(\"Training   Loss: %f\" %loss_train[i])\n",
    "    if mymodel.verbose: print(\"Validation Loss: %f\" %loss_val[i])\n",
    "    if all(loss_val[max(0, i - patience):i] > min(np.append(loss_val[0:max(0, i - patience)], 200))) and i > patience:\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "    stop = time.time()\n",
    "    duration = start - stop\n",
    "    print(duration)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"firsttryhistory.h5\", \"w\")\n",
    "f.create_dataset('train_loss', data= np.asarray(loss_train), compression='gzip')\n",
    "f.create_dataset('val_loss', data= np.asarray(loss_val), compression='gzip')\n",
    "\n",
    "# the best model\n",
    "torch.save(mymodel.state_dict(), 'C:/Users/anrun/JEDInet-code/models/best_model.params')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalloss=[]\n",
    "models=[]\n",
    "models.append(mymodel)\n",
    "loss_val = loss_val[loss_val>0]\n",
    "finalloss.append(loss_val[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7125085610151303]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Validation\\jetImage_5_30p_20000_30000.h5\n",
      "4800000\n",
      "(10000, 30, 16) (10000, 5)\n",
      "../data/Validation\\jetImage_5_30p_40000_50000.h5\n",
      "4800000\n",
      "(20000, 30, 16) (20000, 5)\n",
      "../data/Validation\\jetImage_4_30p_50000_60000.h5\n",
      "4800000\n",
      "(30000, 30, 16) (30000, 5)\n",
      "../data/Validation\\jetImage_6_30p_10000_20000.h5\n",
      "4800000\n",
      "(40000, 30, 16) (40000, 5)\n",
      "../data/Validation\\jetImage_5_30p_80000_90000.h5\n",
      "4800000\n",
      "(50000, 30, 16) (50000, 5)\n",
      "../data/Validation\\jetImage_6_30p_50000_60000.h5\n",
      "4800000\n",
      "(60000, 30, 16) (60000, 5)\n",
      "../data/Validation\\jetImage_6_30p_70000_80000.h5\n",
      "4800000\n",
      "(70000, 30, 16) (70000, 5)\n",
      "../data/Validation\\jetImage_6_30p_40000_50000.h5\n",
      "4800000\n",
      "(80000, 30, 16) (80000, 5)\n",
      "../data/Validation\\jetImage_6_30p_80000_90000.h5\n",
      "4800000\n",
      "(90000, 30, 16) (90000, 5)\n",
      "../data/Validation\\jetImage_6_30p_30000_40000.h5\n",
      "4800000\n",
      "(100000, 30, 16) (100000, 5)\n",
      "../data/Validation\\jetImage_5_30p_30000_40000.h5\n",
      "4800000\n",
      "(110000, 30, 16) (110000, 5)\n",
      "../data/Validation\\jetImage_6_30p_60000_70000.h5\n",
      "4800000\n",
      "(120000, 30, 16) (120000, 5)\n",
      "../data/Validation\\jetImage_5_30p_50000_60000.h5\n",
      "4800000\n",
      "(130000, 30, 16) (130000, 5)\n",
      "../data/Validation\\jetImage_4_30p_80000_90000.h5\n",
      "4800000\n",
      "(140000, 30, 16) (140000, 5)\n",
      "../data/Validation\\jetImage_6_30p_0_10000.h5\n",
      "4800000\n",
      "(150000, 30, 16) (150000, 5)\n",
      "../data/Validation\\jetImage_5_30p_70000_80000.h5\n",
      "4800000\n",
      "(160000, 30, 16) (160000, 5)\n",
      "../data/Validation\\jetImage_5_30p_0_10000.h5\n",
      "4800000\n",
      "(170000, 30, 16) (170000, 5)\n",
      "../data/Validation\\jetImage_5_30p_10000_20000.h5\n",
      "4800000\n",
      "(180000, 30, 16) (180000, 5)\n",
      "../data/Validation\\jetImage_4_30p_60000_70000.h5\n",
      "4800000\n",
      "(190000, 30, 16) (190000, 5)\n",
      "../data/Validation\\jetImage_5_30p_60000_70000.h5\n",
      "4800000\n",
      "(200000, 30, 16) (200000, 5)\n",
      "../data/Validation\\jetImage_4_30p_70000_80000.h5\n",
      "4800000\n",
      "(210000, 30, 16) (210000, 5)\n",
      "../data/Validation\\jetImage_6_30p_20000_30000.h5\n",
      "4800000\n",
      "(220000, 30, 16) (220000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "X_test = np.array([])\n",
    "Y_test = np.array([])\n",
    "inputFiles = glob.glob(\"../data/Validation/jetImage*_%sp*.h5\" %nParticles)   \n",
    "#inputFiles = glob.glob(\"/data/ML/mpierini/hls-fml/VALIDATION/jetImage_9_%sp*.h5\" %nParticles)\n",
    "#inputFiles = glob.glob(\"/data/ml/mpierini/hls-fml/VALIDATION/jetImage_9_%sp*.h5\" %nParticles)\n",
    "random.shuffle(inputFiles)\n",
    "for fileINname in inputFiles:\n",
    "    print(fileINname)\n",
    "    f = h5py.File(fileINname, 'r')\n",
    "    myFeatures = np.array(f.get('jetConstituentList'))\n",
    "    myTarget = np.array(f.get('jets')[0:,-6:-1])\n",
    "    print(myFeatures.size)\n",
    "    X_test = np.concatenate([X_test,myFeatures], axis = 0) if X_test.size else myFeatures\n",
    "    Y_test = np.concatenate([Y_test,myTarget], axis = 0) if Y_test.size else myTarget\n",
    "    print(X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Training\\\\jetImage_4_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_20000_30000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_70000_80000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_60000_70000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_30000_40000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_1_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_80000_90000.h5',\n",
       " '../data/Training\\\\jetImage_2_30p_10000_20000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_50000_60000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_40000_50000.h5',\n",
       " '../data/Training\\\\jetImage_0_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_4_30p_0_10000.h5',\n",
       " '../data/Training\\\\jetImage_3_30p_40000_50000.h5']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split\n",
    "X_test, Y_test = shuffle(X_test, Y_test, random_state=1)\n",
    "\n",
    "X_test = np.swapaxes(X_test, 1, 2)\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "Y_test = torch.FloatTensor(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-40c5afb67042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mOtot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmyO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5f29f792e3d7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mOrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mOrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-5f29f792e3d7>\u001b[0m in \u001b[0;36mtmul\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mx_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0my_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# extract the O matrix and the category output [TBF]\n",
    "predict_test = []\n",
    "lst = []\n",
    "Otot = []\n",
    "for j in torch.split(X_test, batch_size):\n",
    "    a, myO = mymodel(j)\n",
    "    a = a.cpu().data.numpy()\n",
    "    myO = torch.sum(myO, dim=1)\n",
    "    myO = myO.cpu().data.numpy()\n",
    "    # sum over particles\n",
    "    lst.append(a)\n",
    "    Otot.append(myO)\n",
    "    \n",
    "predicted = Variable(torch.FloatTensor(np.concatenate(lst)))\n",
    "predicted = torch.nn.functional.softmax(predicted, dim=1)\n",
    "predict_test = predicted.data.numpy()\n",
    "\n",
    "O_predicted = Variable(torch.FloatTensor(np.concatenate(Otot)))\n",
    "O_predicted_test = O_predicted.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-2c85386f9253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    147\u001b[0m             raise RuntimeError(\n\u001b[0;32m    148\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             raise AssertionError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EPE_ML\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#### get the ROC curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
